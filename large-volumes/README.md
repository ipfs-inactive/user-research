# IPFS user research | Large volumes

üéØ**How might one store and transfer terabytes or petabytes of data using IPFS?** 

- [Background](#background)
- [Work so far](#work-so-far)

## Background

([Original work plan](https://docs.google.com/document/d/1rNYIg6sQoRYDVcvQ8oPbJ4ov6Dbque5Hcvn44q7qk4A/edit?usp=sharing)üîí)

This area of focus is part of a project to document user journeys around key IPFS use cases.

We want to:
* Understand the motivations, needs, context, constraints, etc of data managers who are handling large volumes of data
* Identify ‚Äúcritical paths‚Äù for users to successfully navigate our documentation, APIs, and support channels when managing large volumes of data on IPFS 
* Reinforce relationships with strategic partners who have expressed interest in using IPFS to manage large volumes of data
* Establish clear narrative for explaining the relevance of [Data Together](https://datatogether.org/) in this context

It also presents a useful opportunity to continue work around load-testing IPFS and identifying points of pain for these users.

_Note: All of these user journeys should focus on storage for Access and Preservation rather than focusing on Discovery. In action, this means you should only focus on metadata like versioning, provenance, etc insofar as they are necessary in order to support access and preservation. Discovery is a huge topic of its own that we are not tackling yet. Yes, gather info about needs around discovery & metadata related topics but do not scurry down those rabbit holes._

## Work so far

**TODO** These reports either need to be transferred to this repo, or written and then transferred

- Kelani's report
- ESIP conference report
- Proto-user journey from jonnycrunch at Developers Meetings in Berlin
- Michelle B's work with Data Together
